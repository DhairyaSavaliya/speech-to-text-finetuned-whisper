# ğŸ™ï¸ Fine-Tuned Whisper for Speech-to-Text (English)

> **Fine-tuning OpenAIâ€™s Whisper model for English Automatic Speech Recognition (ASR)** with deployment via Gradio.  
> Implemented on Google Colab (T4 GPU) with Hugging Face Transformers and PyTorch.

---

## ğŸ§  Overview

This project fine-tunes **Whisper**, OpenAIâ€™s state-of-the-art speech recognition model, on a **custom English dataset** to improve transcription accuracy on real-world speech samples (accents, noise, conversational audio).

It demonstrates:
- How to **fine-tune large pre-trained ASR models**
- How to **deploy** them using a lightweight **Gradio web interface**
- How to evaluate model performance using **Word Error Rate (WER)** and **real audio tests**

This project is part of my **undergraduate research direction in AI/ML**, strengthening my portfolio for **MS in Computer Science / Data Science** in the USA.

---

## âš™ï¸ Key Highlights

âœ… Fine-tuned Whisper base model on a custom English dataset  
âœ… End-to-end pipeline: data preprocessing â†’ training â†’ evaluation â†’ deployment  
âœ… Evaluation via **Word Error Rate (WER)** metric  
âœ… Lightweight **Gradio app** for real-time speech transcription  
âœ… Transparent documentation of training logs and architecture choices  

---

## ğŸ—ï¸ Project Architecture

data/
 â”œâ”€â”€ train/
 â”œâ”€â”€ test/
 â””â”€â”€ custom_audio_samples/
notebooks/
 â”œâ”€â”€ ASR_Fine_Tuned.ipynb      # Fine-tuning workflow
 â””â”€â”€ Speech_to_Text_Baseline.ipynb  # Pretrained Whisper demo & deployment
assets/
 â””â”€â”€ demo_screenshot.png
requirements.txt
README.md


---

## ğŸš€ Workflow

1. **Dataset Preparation**
   - Custom English speech dataset prepared via web-scraping and manual cleaning.  
   - Converted to `.wav` format with consistent sample rates.  
   - Transcripts formatted to Hugging Face Dataset format.

2. **Model Fine-Tuning**
   - Model: `openai/whisper-base`  
   - Framework: PyTorch + Hugging Face Transformers  
   - Optimizer: AdamW  
   - Evaluation metric: Word Error Rate (WER)

3. **Evaluation**
   - Baseline Whisper model tested on LibriSpeech subset  
   - Fine-tuned version tested on domain-specific dataset  
   - Accuracy improvement observed qualitatively (lower transcription errors, better accent handling)

4. **Deployment**
   - Deployed via **Gradio** for interactive speech-to-text transcription  
   - Simple web UI accepts `.wav` input or microphone input and displays real-time text output

---

## ğŸ§ª Example Output

| Model | Sample Input | Predicted Text | WER |
|--------|---------------|----------------|------|
| Whisper Base | â€œhello everyone welcomeâ€¦â€ | â€œhello everyone welcomeâ€¦â€ | â€” |
| Fine-tuned | â€œmy name is beva and i study aiâ€ | â€œmy name is beva and i study aiâ€ | â€” |

---

## ğŸ–¼ï¸ Deployment Preview

| Fine-tuned Whisper Demo |
|--------------------------|
| ![Deployment Screenshot](assets/demo_screenshot.png) |

*(Executed in Google Colab using Gradio â€” can be replicated easily.)*

---

## ğŸ§° Installation

```bash
# clone the repository
git clone https://github.com/<yourusername>/speech-to-text-finetuned-whisper.git
cd speech-to-text-finetuned-whisper

# install dependencies
pip install -r requirements.txt

ğŸ’¬ Future Work

Quantitative benchmarking on Common Voice dataset

Experimenting with Whisper Medium or Large for multilingual ASR

Exporting model as a FastAPI endpoint or Hugging Face Space

ğŸ“„ Tech Stack
Category	Tools
Framework	PyTorch, Hugging Face Transformers
Deployment	Gradio
Audio Processing	Librosa, SoundFile, Torchaudio
Evaluation	JiWER, Evaluate
Environment	Google Colab (T4 GPU)
ğŸ§‘â€ğŸ’» Author

Beva
B.Tech Computer Science | AI/ML Research Enthusiast
Passionate about Deep Learning, Speech Recognition, and Computer Vision

ğŸŒ GitHub : https://github.com/DhairyaSavaliya

ğŸ“§ Email : dhairyasavaliya73@gmail.com
